# -*- coding: utf-8 -*-
"""glmAPIs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OJQ1gkYAcHU3hUQsXDKaoZvd1hnAVmyj
"""

import statsmodels.api as sm
import statsmodels.formula.api as smf
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import files
files.upload()

# creating the dataframes
df = pd.read_csv('car_insurance_dataset.csv')
df.columns

# drop unnecessary columns
df.drop(['Driver_ID', 'Policy_ID', 'Vehicle_ID'], axis=1, inplace=True)

# handle missing values in the dataset
df.dropna(axis=1, inplace=True)

# handle categorical variables
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
categorical_cols

categorical_cols_values = {}

for col in categorical_cols:
    categorical_cols_values[col] = df[col].unique().tolist()

categorical_cols_values

# all the variables are nominal we will label them
encoder =  LabelEncoder()
for col in categorical_cols:
    df[col] = encoder.fit_transform(df[col]) + 1

df

# @title Age

from matplotlib import pyplot as plt
df['Age'].plot(kind='hist', bins=20, title='Age')
plt.gca().spines[['top', 'right',]].set_visible(False)

corr_matrix = df.corr()
plt.figure(figsize=(10,6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.show()

df_new = df.drop(['Vehicle_Age','Annual_Income', 'Driving_Experience', 'Engine_Capacity', 'Claim_Frequency', 'Coverage_Level'],axis=1)



def premium_model(df):
  formula = 'Annual_Premium ~ Gender + Marital_Status + Vehicle_Type + Fuel_Type + Claim_Cost'

  model = smf.glm(formula=formula, data=df, family=sm.families.Gamma(link=sm.families.links.Log()))

  return model

# generate columns for
x_premium = df_new.drop('Annual_Premium', axis=1)
y_premium = df_new['Annual_Premium']

# separating data for testing and training
x_premium_train, x_premium_test, y_premium_train, y_premium_test = train_test_split(x_premium, y_premium, test_size=0.3)

df_prem_train = pd.concat([x_premium_train, y_premium_train], axis=1)
df_prem_test = pd.concat([x_premium_test, y_premium_test], axis=1)

prem_model = premium_model(df_prem_train)
results = prem_model.fit()
results.summary()

# make predictions for the remaining dataset
y_pred = results.predict(df_prem_test)

mae = mean_absolute_error(y_premium_test, y_pred)
mse = mean_squared_error(y_premium_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_premium_test, y_pred)
print(f"MAE: {mae:.2f}")
print(f"MSE: {mse:.2f}")
print(f"rmse: {rmse:.2f}")
print(f"R²: {r2:.2f}")

y_pred

df_claim = df.drop(['Gender', 'Annual_Income', 'Coverage_Level'],axis=1)

def claim_model(df):
  formula = 'Claim_Cost ~ Vehicle_Age + Marital_Status + Vehicle_Type + Fuel_Type + Engine_Capacity + Driving_Experience + Age + Claim_Frequency'

  model = smf.glm(formula=formula, data=df, family=sm.families.Gamma(link=sm.families.links.Log()))

  return model

# prediciton columns
x_claim = df_claim.drop('Claim_Cost', axis=1)
y_claim = df_claim['Claim_Cost']

x_claim_train, x_claim_test, y_claim_train, y_claim_test = train_test_split(x_claim, y_claim, test_size=0.3)

df_claim_train = pd.concat([x_claim_train, y_claim_train], axis=1)
df_claim_test = pd.concat([x_claim_test, y_claim_test], axis=1)

claim_model = claim_model(df_claim_train)
results = claim_model.fit()
results.summary()

# make predictions for the remaining dataset
y_pred = results.predict(df_claim_test)

mae = mean_absolute_error(y_claim_test, y_pred)
mse = mean_squared_error(y_claim_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_claim_test, y_pred)
print(f"MAE: {mae:.2f}")
print(f"MSE: {mse:.2f}")
print(f"rmse: {rmse:.2f}")
print(f"R²: {r2:.2f}")

y_pred